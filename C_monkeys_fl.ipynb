{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6afbebe5-0d74-47dc-bfe1-1a81b972b931",
   "metadata": {},
   "source": [
    "# Making health predictions about the monkeys using Federated Learning (FL)\n",
    "- FL allows for edge training and synching of models \n",
    "    - makes data private and overcomes the siloing/pooling of data into a centralized place\n",
    "- Using PySyft as it is futher developed than Intel's OpenFL\n",
    "- Attempt to train for each monkey as an edge \"pateint\" \n",
    "- Set up for incorporation of other data too\n",
    "\n",
    "Initially following this example (https://towardsdatascience.com/federated-learning-3097547f8ca3, GitHub: https://github.com/saranshmanu/Federated-Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3759e3-d781-4448-aebb-041b2e2d03b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.federated import utils\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1642766-6b20-4f3b-8d83-b3893102c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.test_batch_size = 8\n",
    "        self.batch_size = 8\n",
    "        self.log_interval = 10\n",
    "        self.seed = 1\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058705b3-9df0-4601-9740-9a8cc577b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/boston_housing.pickle','rb') as f:\n",
    "    ((x, y), (x_test, y_test)) = pickle.load(f)\n",
    "\n",
    "x = torch.from_numpy(x).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f9822-3d7c-4092-b293-d48fe9917913",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean(0, keepdim=True)\n",
    "dev = x.std(0, keepdim=True)\n",
    "mean[:, 3] = 0.\n",
    "dev[:, 3] = 1.\n",
    "x = (x - mean) / dev\n",
    "x_test = (x_test - mean) / dev\n",
    "train = TensorDataset(x, y)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b7d94-0373-484f-a930-3ca4001004ba",
   "metadata": {},
   "source": [
    "# Creating architecture of the Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e22b2-cee8-42be-b80f-b7fbcdaf5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc4 = nn.Linear(24, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7b033-1692-4252-9397-5e18bb97a508",
   "metadata": {},
   "source": [
    "# Connect to the workers or the devices for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f20f4-62c3-42b7-a120-f04845c1f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "bob_worker = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice_worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "# kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook}\n",
    "# alice = WebsocketClientWorker(id='alice', port=8779, **kwargs_websocket)\n",
    "# bob = WebsocketClientWorker(id='bob', port=8778, **kwargs_websocket)\n",
    "compute_nodes = [bob_worker, alice_worker]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254428a-8a34-4bdf-8f55-ee06231dc0de",
   "metadata": {},
   "source": [
    "# Though data will be available offline for federated learning with the workers but here we are sending the data over to the workers for training with ondevice capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e362c2c-0f4b-4589-8622-2a900bbe2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = (list(), list())\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cca72f-aab0-40ac-a49a-ee9ad0517e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = Net()\n",
    "alices_model = Net()\n",
    "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)\n",
    "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d350bb-dd13-43f2-b503-1d4e47109059",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [bobs_model, alices_model]\n",
    "optimizers = [bobs_optimizer, alices_optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cc693-49c6-4ef4-bb2e-e26c9d640760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5d378-78ec-4bc3-b46f-d3cd11913fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, target, model, optimizer):\n",
    "    model.send(data.location)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(data)\n",
    "    loss = F.mse_loss(prediction.view(-1), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    for data_index in range(len(remote_dataset[0])-1):\n",
    "        for remote_index in range(len(compute_nodes)):\n",
    "            data, target = remote_dataset[remote_index][data_index]\n",
    "            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n",
    "        for model in models:\n",
    "            model.get()\n",
    "        return utils.federated_avg({\n",
    "            \"bob\": models[0],\n",
    "            \"alice\": models[1]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8dc24c-feda-49b9-88a1-915d6d3dd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(federated_model):\n",
    "    federated_model.eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        output = federated_model(data)\n",
    "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item()\n",
    "        predection = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f6852-f47f-4bc6-9778-b84f5aef5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch Number {epoch + 1}\")\n",
    "    federated_model = train()\n",
    "    model = federated_model\n",
    "    test(federated_model)\n",
    "    total_time = time.time() - start_time\n",
    "    print('Communication time over the network', round(total_time, 2), 's\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cc5ee-fe32-4fe2-b397-e89a53b46dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f65a8-92b8-44ed-96e1-18d10078b6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909310d-05fb-4596-b883-293ca1f740c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cb514-d128-4b84-9e30-8acca49096af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294512b5-1feb-40f6-862e-d0cd8670b561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec4c0b-7e44-4afc-b76a-8fda1e10fe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
